# TODO: Write logic to do tool call in one place and add it's result
import json
import logging
from typing import Annotated
from typing_extensions import TypedDict
from dotenv import load_dotenv
from langgraph.graph.message import add_messages
from langgraph.graph import StateGraph, START, END
from ollama import ChatResponse, chat


from ddgs import DDGS

logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("react_agent.log"),
    ]
)
logger = logging.getLogger(__name__)

load_dotenv()
MODEL = "llama3-8b-8192"

def web_search(query: str):
    logging.info(f"web_search query {query}")
    results = DDGS().text(query, max_results=5)
    print(results)
    return results

def calculate(expression: str):
    logging.info(f"calculate expression {expression}")
    return eval(expression)

class State(TypedDict):
    messages: list
    action: str
    observation: str

AVAILABLE_TOOLS: str = """
    1. web_search
        Searches the web using DuckDuckGo and returns top 5 results about query.
        Usage:
            web_search("machine learning") -> Returns list of search results
    2. calculate
        Evaluates a mathematical expression and returns the result.
        Usage:
            calculate("2 + 3") -> Returns 5
            calculate("10 * 5") -> Returns 50
            calculate("2 ** 3") -> Returns 8
    
        Warning: Uses eval() which can be dangerous with untrusted input
    """

def get_system_prompt(available_tools: str, observation: str)->str:
    system_prompt = """You are an AI Agent. You run in Think -> Action -> Observation Loop
    Think about user task and check observation and return which tool from available tools to use. 
    IMPORTANT: Return ONLY raw JSON, no markdown formatting, no code blocks, no explanations.
    Your output should be in following JSON format:
    {{
        "tool_name": str,
        "args: str
    }}
    If you think, it is final answer then use "END" as tool_name. 
    If you can't decide which tool to use then return your output in string.
    Valid response formats:
    {{"tool_name": "web_search", "args": "your query"}}
    {{"tool_name": "calculate", "args": "2 + 3"}}
    {{"tool_name": "END", "args": "final answer here"}}

    If you can't decide, return a plain string explaining your reasoning.
    You have access to following available tools.
    AVAILABLE TOOLS: {available_tools}
    Observation: {observation}
    """.format(available_tools=available_tools, observation=observation)
    return system_prompt     

def init(state: State):
    system_prompt: str = get_system_prompt(available_tools=AVAILABLE_TOOLS, observation="")
    state["messages"] = [{"role": "system", "content": system_prompt}] + state["messages"]
    return state

def think(state: State):
    if state["messages"] and state["observation"]:
        updated_system_prompt = get_system_prompt(available_tools=AVAILABLE_TOOLS, observation=state["observation"])
        state["messages"][0]["content"] = updated_system_prompt
    response: ChatResponse = chat(model='gemma3:27b', messages=state["messages"])
    state["messages"].append({
        "role": "assistant",
        "content": response.message.content
    })
    return state

def act(state: State):
    last_message = state["messages"][-1]["content"]
    try:
        tool_call = json.loads(last_message)
    except json.JSONDecodeError:
        state["observation"] = f"Error: Invalid JSON. JSON Decode Error. Please return valid JSON or 'END'"
    else:
        if tool_call["tool_name"] == "calculate":
            try:
                tool_result = calculate(expression=tool_call["args"])
            except Exception as e:
                error_msg = f"Tool Error : {str(e)}"
                state["messages"].append({
                    "role": "tool",
                    "name": "calculate",
                    "content": error_msg
                }) 
                state["observation"] = error_msg               
            else:
                state["observation"] = f"Tool Result:: {tool_result}"
                state["messages"].append({
                    "role": "tool",
                    "name": "calculate",
                    "content": f"{tool_result}"
                })                
    return state

def stream_graph_updates(user_input: str):
    for event in graph.stream({"messages": [{"role": "user", "content": user_input}], "action": "", "observation": ""}):
        for node_name, value in event.items():
            print("Assistant ", value["messages"][-1])
            pass

def should_end(state: State):
    print("in should end")
    try:
        last_message = state["messages"][-1]
        content = last_message["content"]
        if isinstance(content, str):
            content = json.loads(content)
            return content["tool_name"] == "END"
        
    except Exception as e:
        pass
    return True

    

if __name__ == "__main__":
    graph_builder = StateGraph(State)
    graph_builder.add_node("init", init)
    graph_builder.add_node("think", think)
    graph_builder.add_node("act", act)

    graph_builder.add_edge(START, "init")
    graph_builder.add_edge("init", "think")
    graph_builder.add_edge("think", "act")
    graph_builder.add_conditional_edges("act", should_end, {True: END, False: "think"})
    graph = graph_builder.compile()
    
    stream_graph_updates(user_input="what is time now? and then add it 60 seconds to it")
